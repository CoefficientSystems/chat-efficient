{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "368dccec-1d58-4167-a50d-01c56d98c24e",
   "metadata": {},
   "source": [
    "<img src=\"../images/obt-banner.png\" width=1200>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaa8042-8f66-4de9-b9cb-3a2383c2e5e0",
   "metadata": {},
   "source": [
    "# Build Your Own Private ChatGPT Super-Assistant Using Streamlit, LangChain, Chroma & Llama 2\n",
    "## OpenAI Demo\n",
    "**Questions?** contact@coefficient.ai / [@CoefficientData](https://twitter.com/CoefficientData)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9dfd7f-dcc6-418c-bc6b-02c7771e07fa",
   "metadata": {},
   "source": [
    "## 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73809ac-30df-4182-8d69-e49d9ccc60b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from utils import scrape_page\n",
    "\n",
    "load_dotenv();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a2f7f0-8d61-4feb-b4c7-6cfff3c7cf9b",
   "metadata": {},
   "source": [
    "## 1. OpenAI API Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42da2e1d-4461-4299-899b-f6f3ac083e04",
   "metadata": {},
   "source": [
    "### Set up client and context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298d371f-4ae0-48ca-ae4b-c1c82b0801e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you've entered your OpenAI API key in the .env file\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9141d9e-4d5d-4419-bbde-e957dc656842",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a55942-8bd7-4433-9b0f-86dab89e8092",
   "metadata": {},
   "source": [
    "### Add prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc208d-9693-4787-8edd-1fcfb438655c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain how GPT works using a limerick.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b4aae4-96e9-4e05-b992-420d471a74b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0151377-a83a-4925-a665-df7e1347b46d",
   "metadata": {},
   "source": [
    "### Get completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ec337b-822a-440a-95c5-e42614e78ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "completion = client.chat.completions.create(model=model, messages=messages)\n",
    "response = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e679ed-8154-4af7-8286-2afc1041aba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5acf31-517b-4f0b-bb2e-7923a7a1ad5a",
   "metadata": {},
   "source": [
    "### Add response to context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ef9052-b131-46ba-80a7-38340fdfd391",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"assistant\", \"content\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e00765-ea23-407b-9436-24b3f4754b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1c3199-6f13-4d0f-9deb-bddf263da6a6",
   "metadata": {},
   "source": [
    "### New prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d2cf9d-66c0-47d0-aee0-ff49b443d333",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"That's great! Now do it as a haiku.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81dfb7f-891f-4f4c-909b-bb3f16bef4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e28200-3c2b-45dc-a8bc-b0c9c17b7ea6",
   "metadata": {},
   "source": [
    "### Get completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120704a-b7b1-4a39-befe-2f486abbd7a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "completion = client.chat.completions.create(model=model, messages=messages)\n",
    "response = completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c11b2-00ce-4278-8c35-1f495d0e00ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de67362c-797d-4473-aa47-c207b1ad7bfc",
   "metadata": {},
   "source": [
    "### Add response to context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b3f5a-4601-467a-9140-7ecd54ace14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({\"role\": \"assistant\", \"content\": response})\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7075a0d-cf15-478e-8949-2e82b8a82969",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d5091-3573-40f1-b14c-ec2feb9e7af8",
   "metadata": {},
   "source": [
    "## 2. How to cache with joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d95f8d1-0b19-4306-8edc-55e23d730ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(x):\n",
    "    time.sleep(3)\n",
    "    return x * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb41ea3-6633-4451-937a-a7d439c1a97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate(666)  # slow üò¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ca113-dbd7-470a-80a8-8bbbb90be9f5",
   "metadata": {},
   "source": [
    "‚¨á\n",
    "<br/>\n",
    "‚¨á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07529c2-c8f6-447d-ae00-e1704c7f4245",
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import Memory\n",
    "\n",
    "memory = Memory(\"./cache\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e4989d-d5e4-4aa2-ba5b-9305939462d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def calculate(x):\n",
    "    time.sleep(3)\n",
    "    return x * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90923412-f2cb-462d-a61f-4a5e0ee5553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate(666)  # slow üò¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1989009a-033e-43e2-ae8a-a30fcf4df457",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate(666)  # fast! üèÉ‚Äç‚ôÇÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6047548-7d9d-43d5-acf8-4ba98469a028",
   "metadata": {},
   "source": [
    "‚¨á\n",
    "<br/>\n",
    "‚¨á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9be681-2363-43a3-be45-657d84c3c3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda8e53d-7b30-47f3-9489-b202c2fb9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "calculate(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de5fede-4f2c-41df-8881-2831308b539f",
   "metadata": {},
   "source": [
    "\n",
    "‚¨á\n",
    "<br/>\n",
    "‚¨á"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e985e43-d8ef-4c31-bbb7-15965ca5c9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear the cache so I can give this talk again!\n",
    "memory.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885f8c47-c10c-4e3f-8e77-7c910b69579a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10fc707-5254-4c62-8bc3-fdd49e019a02",
   "metadata": {},
   "source": [
    "## 3. Make a cached OpenAI function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3200cf-3246-4f85-89be-5832a556b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memory.cache\n",
    "def generate_response(prompt, context):\n",
    "    context.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    completion = client.chat.completions.create(model=model, messages=messages)\n",
    "    response = completion.choices[0].message.content\n",
    "    context.append({\"role\": \"assistant\", \"content\": response})\n",
    "\n",
    "    return response, context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cced3e-8d2e-4c1b-89ff-2cfd0137ebb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-3.5-turbo\"\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a sales assistant for the awesome machine learning consultancy, Coefficient.\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658db76-a1d2-465e-877d-55b856521578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a prompt\n",
    "prompt = f\"\"\"\n",
    "Here's some information about Coefficient:\n",
    "\n",
    "{scrape_page('https://coefficient.ai')}\n",
    "\n",
    "Please summarise Coefficient's services in 3 bullet points.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dfa44c-842b-49cf-a592-de71bfbbe94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Get response & update context\n",
    "response, context = generate_response(prompt, context=messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854c24b4-a388-4f47-8899-9540cb53cbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1fa4b3-e4ac-468d-bd3b-0ebf7448b5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# That doesn't quite hit the mark, let's try again...\n",
    "\n",
    "response, context = generate_response(\n",
    "    prompt=\"Can you make it sound more fun? Use some emoji?\",\n",
    "    context=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c59dda-7d3b-48f8-ad54-31591b04adb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19aad1c-c564-4919-aec2-e7d856c3f281",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf10192-c811-4238-8194-ebd4e8a7d07a",
   "metadata": {},
   "source": [
    "## 4. Exercise: Build your own LLM tool\n",
    "\n",
    "> **Exercise**\n",
    "> Time to get creative! Adapt the cached OpenAI function to make it do something else. Here's some ideas to get you thinking:\n",
    "> - Ask it to summarise a movie using emoji (or the reverse, to guess a movie from emoji).\n",
    "> - Read in a CSV using pandas `pd.read_csv()` containing customer feedback, and ask it to summarise the top 5 issues with recommended actions.\n",
    "> - Use the provided `scrape_page()` function to build an auto-summariser for any scrapable webpage, such as GOV.UK pages or articles.\n",
    "> - Adapt it to generate a list of ideas for any problem you supply, and then ask it to provide ideas for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23a31a7-8007-49c1-82ef-03ad938a834c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f14200-dfc9-436d-b624-b7c061c57736",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>About</strong>\n",
    "    <p>\n",
    "        This notebook has been made by <a href=\"https://twitter.com/john_sandall\">@John_Sandall</a>. I run training workshops in Python, data science and data engineering.\n",
    "    </p><br/>\n",
    "    <p>\n",
    "        You can follow my free <a href=\"https://github.com/pydatabristol/workshops/tree/master/workshop_2019_10_28_first_steps\"><em>First Steps with Python</em></a> and <a href=\"https://github.com/pydatabristol/workshops/tree/master/workshop_2020_02_27_first_steps_with_pandas\"><em>First Steps with pandas</em></a> workshops for free as part of <a href=\"https://www.meetup.com/PyData-Bristol/\">PyData Bristol's</a> <i>Zero To Hero</i> workshop series. I now run the <a href=\"https://www.meetup.com/pydata-london-meetup/\">PyData London Meetup</a>, a great place to learn more and meet other data professionals every month.\n",
    "    </p><br/>\n",
    "    <p>\n",
    "        I am the Founder of data science consultancy <a href=\"https://coefficient.ai/\">Coefficient</a>. If you would like to work with us, our team can help you with your <a href=\"https://www.youtube.com/watch?v=qBvO3fyl1lk\">data science</a>, <a href=\"https://coefficient.ai/#services-page\">software engineering</a>, <a href=\"https://www.youtube.com/watch?v=na7yqvz5-B4\">modern data stack</a> or <a href=\"https://coefficient.ai/#machine-learning-page\">machine learning</a> projects as an on-demand resource. We can also create <a href=\"https://coefficient.ai/#training-page\">bespoke training workshops</a> adapted to your industry, virtual or in-person, with training clients currently including BNP Paribas, EY, the Met Police and the BBC.\n",
    "    </p>\n",
    "</div>\n",
    "\n",
    "[![about](../images/about-me.jpeg)](https://coefficient.ai)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (chatefficient)",
   "language": "python",
   "name": "chatefficient"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
